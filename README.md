# NLU Assignment 1
## How to run files
For generate_token.sh run command <br />
```
bash random_sentence_gen.sh
```
For language_models.py run command <br />
```
python3 language_models.py
```
No need to run generate_sentence.py as that is run by random_sentence_gen.sh


## Part A:Language Models

Using Brown and Gutenburg corpus from nltk.
For simple uni-gram backoff:<br />
      Train Data = 90% of total corpus <br />
      Test Data = 10% of total corpus
      
For simple bi-gram backoff:<br />
      Train Data = 90% of total corpus <br />
      Test Data = 10% of total corpus
      
For simple tri-gram backoff:<br />
      Train Data = 90% of total corpus <br />
      Test Data = 10% of total corpus
      
      
For simple four-gram backoff:<br />
      Train Data = 90% of total corpus <br />
      Test Data = 10% of total corpus

<br />

## Part B:Token Generation(random ten tokens)
Examples of some sentences of length 10 generated :<br />
      1) Outside the hall I anxiously looked around for the bubbles<br />
      2) Volume 1 was completed in 1950 and published in 1951<br />
      3) The fourth and concluding point will be to estimate the<br />
      4) If the input light distribution falls beyond the visible range<br />
      5) For a blood-chilling ring of terror to the very issue<br />
      <br />
